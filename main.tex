\documentclass{article}
\usepackage{blindtext}
\usepackage{multicol}
\setlength{\columnsep}{1cm}
\title{NLP Fixing Stuff}
\author{Stacy Roberts}

\date{November 2024}

\begin{document}
\maketitle

\begin{multicols*}{2}

\section*{Abstract}
All human things are subject to decay. And when fate summons, Monarchs must obey.

\section*{Introduction}

Used an electra small model (expand on what that is) with HuggingFace Transformer Trainer (expand on that)
Ran on SNLI dataset. Achieved 89.7\% accuracy without any changes
Approach was to work with Contrast and Adversarial sets

\section*{Model behavior}

Initially trained on either snli dataset (570k elements) for 3 epochs. Achieved 89.7\% accuracy on the evaluation set. Found low confidence on errors but skewed to neutral.
Retrained on a very small subset (10k) for 5 epochs not realizing how big the dataset was, then immediately retrained again on half the dataset (275k) for 5 epochs. Now my accuracy on eval was 88.6\% but the data analysis showed more skew towards irrelevant.

\section*{Analysis of errors}

Stored incorrect predictions into a jsonl file for analysis. Used mathplotlib and other libraries to work on model.
What analysis did I do on the outputs? Can i get dataset cartography to work?

All incorrect predictions came with super low confidence. Nothing higher than 33\%
Incorrect labels scewed more to neutral, entailment and irrelevant were both lower than gold label standard totals.

Seeing some premises that are long with the hypothesis clearly supported/entailed by the later half of the sentence. 

Don't forget to add the chart on length of premise and length of hypothesis of the incorrect predictions
\section*{Attempted Model Updates}

\section*{Conclusion}

\bibliographystyle{apalike}
\bibliography{sample}
\end{multicols*}

\end{document}